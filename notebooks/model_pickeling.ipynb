{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/f8/c7/cfef920b7b457dff6928e824896cb82367650ea127d048ee0b820026db4f/pandas-2.0.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading pandas-2.0.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kelianneheinz/MIDS/courses/W210_Capstone/.venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kelianneheinz/MIDS/courses/W210_Capstone/.venv/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/kelianneheinz/MIDS/courses/W210_Capstone/.venv/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/kelianneheinz/MIDS/courses/W210_Capstone/.venv/lib/python3.9/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kelianneheinz/MIDS/courses/W210_Capstone/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.0.3-cp39-cp39-macosx_10_9_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "Successfully installed pandas-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>blendshapes</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>Pose</th>\n",
       "      <th>Face Obstructed</th>\n",
       "      <th>Hands on Face</th>\n",
       "      <th>Notes</th>\n",
       "      <th>poor_quality</th>\n",
       "      <th>face_angled</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Apparent_Race</th>\n",
       "      <th>head_angle</th>\n",
       "      <th>brow_arch</th>\n",
       "      <th>brow_raise_ratio</th>\n",
       "      <th>lid_brow_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aug-Pose_2_Face-Yoga-Method_416.jpg</td>\n",
       "      <td>[7.1687679792376e-07, 0.0015940895536914468, 0...</td>\n",
       "      <td>[(0.5354241728782654, 0.3942164480686188, -0.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Face-Yoga-Method</td>\n",
       "      <td>F</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.624641</td>\n",
       "      <td>0.600919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zoom-Pose_2_Face-Yoga-Method_416.jpg</td>\n",
       "      <td>[9.191711001221847e-07, 0.0002983348094858229,...</td>\n",
       "      <td>[(0.46912822127342224, 0.2676655948162079, -0....</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Face-Yoga-Method</td>\n",
       "      <td>F</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.580730</td>\n",
       "      <td>0.721970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shear-Pose_2_Face-Yoga-Method_416.jpg</td>\n",
       "      <td>[4.570634928313666e-07, 0.0008711821283213794,...</td>\n",
       "      <td>[(0.4749401807785034, 0.40972456336021423, -0....</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Face-Yoga-Method</td>\n",
       "      <td>F</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.595802</td>\n",
       "      <td>0.678410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoom-Pose_2_Face-Yoga-Method_417.jpg</td>\n",
       "      <td>[1.2624046803466626e-06, 0.0002172658132622018...</td>\n",
       "      <td>[(0.4661442041397095, 0.2637966573238373, -0.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Face-Yoga-Method</td>\n",
       "      <td>F</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0.016876</td>\n",
       "      <td>0.583923</td>\n",
       "      <td>0.712553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flip-Pose_2_Face-Yoga-Method_415.jpg</td>\n",
       "      <td>[5.646483600685315e-07, 0.0006009486387483776,...</td>\n",
       "      <td>[(0.5249334573745728, 0.3435852825641632, -0.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Face-Yoga-Method</td>\n",
       "      <td>F</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.598729</td>\n",
       "      <td>0.670204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Filename  \\\n",
       "0    aug-Pose_2_Face-Yoga-Method_416.jpg   \n",
       "1   zoom-Pose_2_Face-Yoga-Method_416.jpg   \n",
       "2  shear-Pose_2_Face-Yoga-Method_416.jpg   \n",
       "3   zoom-Pose_2_Face-Yoga-Method_417.jpg   \n",
       "4   flip-Pose_2_Face-Yoga-Method_415.jpg   \n",
       "\n",
       "                                         blendshapes  \\\n",
       "0  [7.1687679792376e-07, 0.0015940895536914468, 0...   \n",
       "1  [9.191711001221847e-07, 0.0002983348094858229,...   \n",
       "2  [4.570634928313666e-07, 0.0008711821283213794,...   \n",
       "3  [1.2624046803466626e-06, 0.0002172658132622018...   \n",
       "4  [5.646483600685315e-07, 0.0006009486387483776,...   \n",
       "\n",
       "                                           landmarks  Pose  Face Obstructed  \\\n",
       "0  [(0.5354241728782654, 0.3942164480686188, -0.0...     2                0   \n",
       "1  [(0.46912822127342224, 0.2676655948162079, -0....     2                0   \n",
       "2  [(0.4749401807785034, 0.40972456336021423, -0....     2                0   \n",
       "3  [(0.4661442041397095, 0.2637966573238373, -0.0...     2                0   \n",
       "4  [(0.5249334573745728, 0.3435852825641632, -0.0...     2                0   \n",
       "\n",
       "   Hands on Face Notes  poor_quality  face_angled           Creator Gender  \\\n",
       "0              0   NaN             0            0  Face-Yoga-Method      F   \n",
       "1              0   NaN             0            0  Face-Yoga-Method      F   \n",
       "2              0   NaN             0            0  Face-Yoga-Method      F   \n",
       "3              0   NaN             0            0  Face-Yoga-Method      F   \n",
       "4              0   NaN             0            0  Face-Yoga-Method      F   \n",
       "\n",
       "  Apparent_Race  head_angle  brow_arch  brow_raise_ratio  lid_brow_ratio  \n",
       "0         Asian    0.005279   0.016992          0.624641        0.600919  \n",
       "1         Asian    0.009748   0.016792          0.580730        0.721970  \n",
       "2         Asian    0.003687   0.010946          0.595802        0.678410  \n",
       "3         Asian    0.009163   0.016876          0.583923        0.712553  \n",
       "4         Asian    0.011169   0.010762          0.598729        0.670204  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeds for split\n",
    "SEED = 42\n",
    "\n",
    "# test_creators\n",
    "test_creators = ['Anna-Veronika', 'Blush-with-me-Parmita', 'Doctora-Claudia-Garcia',\n",
    "                 'Gesund-durchs-Leben', 'Goldbeauty', 'Muscle-Watching-L', 'Natty',\n",
    "                 'Pilates-by-Lisa', 'Shanthi-Kasiraj', 'Siddhi-yoga-hindi',\n",
    "                 'templo-del-masaje']\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('/Users/kelianneheinz/MIDS/courses/W210_Capstone/model_data/m1_landmark_summary_blendshape_results_face_angled_augmented.csv')\n",
    "df.loc[df.Pose == 9, 'Pose'] = 6\n",
    "df = df[((df.face_angled != 1) | (df.Pose == 3))]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    '''Returns features as a dataframe'''\n",
    "    features = df.blendshapes.str.replace('\\[', '', regex=True)\\\n",
    "        .str.replace('\\]', '', regex=True).str.replace(\"'\", '', regex=True)\\\n",
    "            .str.split(', ', expand=True).astype(float)\n",
    "    feature_names = {\n",
    "    0:'browDownLeft', 1:'browDownRight', 2:'browInnerUp', 3:'browOuterUpLeft',\n",
    "    4:'browOuterUpRight', 5:'cheekPuff', 6:'cheekSquintLeft', 7:'cheekSquintRight',\n",
    "    8:'eyeBlinkLeft', 9:'eyeBlinkRight', 10:'eyeLookDownLeft', 11:'eyeLookDownRight',\n",
    "    12:'eyeLookInLeft', 13:'eyeLookInRight', 14:'eyeLookOutLeft', 15:'eyeLookOutRight',\n",
    "    16:'eyeLookUpLeft', 17:'eyeLookUpRight', 18:'eyeSquintLeft', 19:'eyeSquintRight',\n",
    "    20:'eyeWideLeft', 21:'eyeWideRight', 22:'jawForward', 23:'jawLeft',\n",
    "    24:'jawOpen', 25:'jawRight', 26:'mouthClose', 27:'mouthDimpleLeft',\n",
    "    28:'mouthDimpleRight', 29:'mouthFrownLeft', 30:'mouthFrownRight',\n",
    "    31:'mouthFunnel', 32:'mouthLeft', 33:'mouthLowerDownLeft',\n",
    "    34:'mouthLowerDownRight', 35:'mouthPressLeft', 36:'mouthPressRight',\n",
    "    37:'mouthPucker', 38:'mouthRight', 39:'mouthRollLower', 40:'mouthRollUpper',\n",
    "    41:'mouthShrugLower', 42:'mouthShrugUpper', 43:'mouthSmileLeft',\n",
    "    44:'mouthSmileRight', 45:'mouthStretchLeft', 46:'mouthStretchRight',\n",
    "    47:'mouthUpperUpLeft', 48:'mouthUpperUpRight', 49:'noseSneerLeft',\n",
    "    50:'noseSneerRight', 51:'tongueOut'\n",
    "    }\n",
    "    features.rename(columns=feature_names, inplace=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/kelianneheinz/MIDS/courses/W210_Capstone/github/website/server/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8951747088186356\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "pose_1_press = ['HisDream', 'Face-Yoga-Expert']\n",
    "df_pose = df[~((df.Creator.isin(pose_1_press)) & (df.Pose == 1))]\n",
    "key_pose = 1\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "features['lid_brow_ratio'] = df['lid_brow_ratio']\n",
    "features['brow_arch'] = df['brow_arch']\n",
    "features['brow_raise_ratio'] = df['brow_raise_ratio']\n",
    "\n",
    "test_creators_p1 = test_creators + ['LibertadDigital']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p1)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p1)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p1)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p1)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'max_depth': 16, 'max_features': 'sqrt',\n",
    "          'min_samples_split': 8, 'n_estimators': 50}\n",
    "model1 = ExtraTreesClassifier(random_state=SEED, **params)\n",
    "model1.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model1.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as pickle file\n",
    "pickle.dump(model1, open(save_dir+'pose_1_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open(save_dir+'p1_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7767441860465117\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "df_pose = df.copy()\n",
    "key_pose = 2\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "\n",
    "test_creators_p2 = test_creators + ['Accents-Way-English']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p2)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p2)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p2)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p2)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'max_depth': 35, 'min_samples_leaf': 5,\n",
    "          'min_samples_split': 2, 'n_estimators': 500}\n",
    "model2 = ExtraTreesClassifier(random_state=SEED, **params)\n",
    "model2.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model2.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as pickle file\n",
    "pickle.dump(model2, open(save_dir+'pose_2_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9562764456981664\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "df_pose = df.copy()\n",
    "key_pose = 3\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "features['head_angle'] = df['head_angle']\n",
    "\n",
    "test_creators_p3 = test_creators + ['Sientete-Bien']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p3)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p3)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p3)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p3)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'colsample_bytree': 0.6, 'gamma': 2.5,\n",
    "          'max_depth': 6, 'min_child_weight': 5,\n",
    "          'subsample': 1.0}\n",
    "model3 = xgb.XGBClassifier(seed=SEED, **params)\n",
    "model3.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model3.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle file\n",
    "pickle.dump(model3, open(save_dir+'pose_3_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open(save_dir + 'p3_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9735182849936949\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "df_pose = df.copy()\n",
    "key_pose = 4\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "\n",
    "test_creators_p4 = test_creators + ['Masumi-Channel']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p4)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p4)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p4)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p4)]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'max_depth': 5, 'min_samples_leaf': 3,\n",
    "          'min_samples_split': 2, 'n_estimators': 400}\n",
    "model4 = ExtraTreesClassifier(random_state=SEED, **params)\n",
    "model4.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model4.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as pickle file\n",
    "pickle.dump(model4, open(save_dir+'pose_4_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986093552465234\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "df_pose = df.copy()\n",
    "key_pose = 5\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "\n",
    "test_creators_p5 = test_creators + ['HisDream']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p5)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p5)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p5)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p5)]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'colsample_bytree': 1.0, 'gamma': 2.5,\n",
    "          'max_depth': 10, 'min_child_weight': 5,\n",
    "          'subsample': 1.0}\n",
    "model5 = xgb.XGBClassifier(random_state=SEED, **params)\n",
    "model5.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model5.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Pickle File\n",
    "pickle.dump(model5, open(save_dir+'pose_5_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8929824561403509\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "df_pose = df.copy()\n",
    "key_pose = 6\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "\n",
    "test_creators_p6 = test_creators + ['Funfitt-with-Susana-Yabar', 'Daniela-Suarez']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p6)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p6)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p6)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p6)]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'max_depth': 35, 'min_samples_leaf': 5,\n",
    "          'min_samples_split': 2, 'n_estimators': 300}\n",
    "model6 = ExtraTreesClassifier(random_state=SEED, **params)\n",
    "model6.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model6.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save standard scaler\n",
    "pickle.dump(scaler, open(save_dir+'scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as pickle file\n",
    "pickle.dump(model6, open(save_dir+'pose_6_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7246537396121885\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "df_pose = df.copy()\n",
    "key_pose = 7\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "\n",
    "test_creators_p7 = test_creators + ['Masumi-Channel', 'Verena-Boix']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p7)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p7)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p7)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p7)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'max_depth': 20, 'min_samples_leaf': 1,\n",
    "          'min_samples_split': 4, 'n_estimators': 400}\n",
    "model7 = ExtraTreesClassifier(random_state=SEED, **params)\n",
    "model7.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model7.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as pickle file\n",
    "pickle.dump(model7, open(save_dir+'pose_7_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9636650868878356\n"
     ]
    }
   ],
   "source": [
    "# Set up Data\n",
    "df_pose = df.copy()\n",
    "key_pose = 8\n",
    "df_pose.loc[df_pose.Pose != key_pose, 'Pose'] = 0\n",
    "df_pose.loc[df_pose.Pose == key_pose, 'Pose'] = 1\n",
    "\n",
    "features = get_features(df_pose)\n",
    "\n",
    "test_creators_p8 = test_creators + ['Valentina-Sadak', 'Yoga-with-Souvik']\n",
    "\n",
    "# Prepare inputs\n",
    "X_train = features[~df_pose.Creator.isin(test_creators_p8)]\n",
    "y_train = df_pose.Pose[~df_pose.Creator.isin(test_creators_p8)]\n",
    "X_test = features[df_pose.Creator.isin(test_creators_p8)]\n",
    "y_test = df_pose.Pose[df_pose.Creator.isin(test_creators_p8)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights_array = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "\n",
    "# Train Model\n",
    "params = {'max_depth': 20, 'min_samples_leaf': 1,\n",
    "          'min_samples_split': 6, 'n_estimators': 500}\n",
    "model8 = ExtraTreesClassifier(random_state=SEED, **params)\n",
    "model8.fit(X_train, y_train, sample_weight=weights_array)\n",
    "y_pred = model8.predict(X_test)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "pickle.dump(model8, open(save_dir+'pose_8_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
